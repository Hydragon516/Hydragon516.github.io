@inproceedings{lee2021regularization,
  abbr={CVPR},
  title={Regularization strategy for point cloud via rigidly mixed sample},
  author={Lee, Dogyoon and Lee, Jaeha and Lee, Junhyeop and Lee, Hyeongmin and Lee, Minhyeok and Woo, Sungmin and Lee, Sangyoun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15900--15909},
  year={2021},
  arxiv={2102.01929},
  code={https://github.com/dogyoonlee/RSMix},
  abstract={Data augmentation is an effective regularization strategy to alleviate the overfitting, which is an inherent drawback of the deep neural networks. However, data augmentation is rarely considered for point cloud processing despite many studies proposing various augmentation methods for image data. Actually, regularization is essential for point clouds since lack of generality is more likely to occur in point cloud due to small datasets. This paper proposes a Rigid Subset Mix (RSMix), a novel data augmentation method for point clouds that generates a virtual mixed sample by replacing part of the sample with shape-preserved subsets from another sample. RSMix preserves structural information of the point cloud sample by extracting subsets from each sample without deformation using a neighboring function. The neighboring function was carefully designed considering unique properties of point cloud, unordered structure and non-grid. Experiments verified that RSMix successfully regularized the deep neural networks with remarkable improvement for shape classification. We also analyzed various combinations of data augmentations including RSMix with single and multi-view evaluations, based on abundant ablation studies.}
}

@inproceedings{lee2022robust,
  abbr={WACV},
  title={Robust lane detection via expanded self attention},
  author={Lee, Minhyeok and Lee, Junhyeop and Lee, Dogyoon and Kim, Woojin and Hwang, Sangwon and Lee, Sangyoun},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={533--542},
  year={2022},
  arxiv={2102.07037},
  code={https://github.com/Hydragon516/ESA-official},
  abstract={The image-based lane detection algorithm is one of the key technologies in autonomous vehicles. Modern deep learning methods achieve high performance in lane detection, but it is still difficult to accurately detect lanes in challenging situations such as congested roads and extreme lighting conditions. To be robust on these challenging situations, it is important to extract global contextual information even from limited visual cues. In this paper, we propose a simple but powerful self-attention mechanism optimized for lane detection called the Expanded Self Attention (ESA) module. Inspired by the simple geometric structure of lanes, the proposed method predicts the confidence of a lane along the vertical and horizontal directions in an image. The prediction of the confidence enables estimating occluded locations by extracting global contextual information. ESA module can be easily implemented and applied to any encoder-decoder-based model without increasing the inference time. The performance of our method is evaluated on three popular lane detection benchmarks (TuSimple, CULane and BDD100K). We achieve state-of-the-art performance in CULane and BDD100K and distinct improvement on TuSimple dataset. The experimental results show that our approach is robust to occlusion and extreme lighting conditions.}
}

@inproceedings{lee2022spsn,
  abbr={ECCV},
  title={Spsn: Superpixel prototype sampling network for rgb-d salient object detection},
  author={Lee, Minhyeok and Park, Chaewon and Cho, Suhwan and Lee, Sangyoun},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXIX},
  pages={630--647},
  year={2022},
  organization={Springer},
  arxiv={2207.07898},
  code={https://github.com/Hydragon516/SPSN},
  abstract={RGB-D salient object detection (SOD) has been in the spotlight recently because it is an important preprocessing operation for various vision tasks. However, despite advances in deep learning-based methods, RGB-D SOD is still challenging due to the large domain gap between an RGB image and the depth map and low-quality depth maps. To solve this problem, we propose a novel superpixel prototype sampling network (SPSN) architecture. The proposed model splits the input RGB image and depth map into component superpixels to generate component prototypes. We design a prototype sampling network so that the network only samples prototypes corresponding to salient objects. In addition, we propose a reliance selection module to recognize the quality of each RGB and depth feature map and adaptively weight them in proportion to their reliability. The proposed method makes the model robust to inconsistencies between RGB images and depth maps and eliminates the influence of non-salient objects. Our method is evaluated on five popular datasets, achieving state-of-the-art performance. We prove the effectiveness of the proposed method through comparative experiments.}
}

@inproceedings{park2022fastano,
  title={FastAno: Fast anomaly detection via spatio-temporal patch transformation},
  author={Park, Chaewon and Cho, MyeongAh and Lee, Minhyeok and Lee, Sangyoun},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2249--2259},
  year={2022}
}

@article{lee2022hierarchically,
  title={Hierarchically Decomposed Graph Convolutional Networks for Skeleton-Based Action Recognition},
  author={Lee, Jungho and Lee, Minhyeok and Lee, Dogyoon and Lee, Sangyoon},
  journal={arXiv preprint arXiv:2208.10741},
  year={2022}
}

@inproceedings{lee2022edgeconv,
  title={Edgeconv with attention module for monocular depth estimation},
  author={Lee, Minhyeok and Hwang, Sangwon and Park, Chaewon and Lee, Sangyoun},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2858--2867},
  year={2022}
}

@inproceedings{cho2023treating,
  title={Treating motion as option to reduce motion dependency in unsupervised video object segmentation},
  author={Cho, Suhwan and Lee, Minhyeok and Lee, Seunghoon and Park, Chaewon and Kim, Donghyeong and Lee, Sangyoun},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={5140--5149},
  year={2023}
}

@inproceedings{lee2023unsupervised,
  title={Unsupervised Video Object Segmentation via Prototype Memory Network},
  author={Lee, Minhyeok and Cho, Suhwan and Lee, Seunghoon and Park, Chaewon and Lee, Sangyoun},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={5924--5934},
  year={2023}
}

@inproceedings{cho2022tackling,
  title={Tackling background distraction in video object segmentation},
  author={Cho, Suhwan and Lee, Heansung and Lee, Minhyeok and Park, Chaewon and Jang, Sungjun and Kim, Minjung and Lee, Sangyoun},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXII},
  pages={446--462},
  year={2022},
  organization={Springer}
}

@inproceedings{park2022saliency,
  title={Saliency detection via global context enhanced feature fusion and edge weighted loss},
  author={Park, Chaewon and Lee, Minhyeok and Cho, MyeongAh and Lee, Sangyoun},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)},
  pages={811--815},
  year={2022},
  organization={IEEE}
}

@inproceedings{lee2022superpixel,
  title={Superpixel Group-Correlation Network for Co-Saliency Detection},
  author={Lee, Minhyeok and Park, Chaewon and Cho, Suhwan and Lee, Sangyoun},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)},
  pages={806--810},
  year={2022},
  organization={IEEE}
}

@article{park2022randomsemo,
  title={RandomSEMO: Normality Learning Of Moving Objects For Video Anomaly Detection},
  author={Park, Chaewon and Lee, Minhyeok and Cho, MyeongAh and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2202.06256},
  year={2022}
}

@article{lee2023adaptive,
  title={Adaptive Graph Convolution Module for Salient Object Detection},
  author={Lee, Yongwoo and Lee, Minhyeok and Cho, Suhwan and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2303.09801},
  year={2023}
}

@article{lee2023guided,
  title={Guided Slot Attention for Unsupervised Video Object Segmentation},
  author={Lee, Minhyeok and Cho, Suhwan and Lee, Dogyoon and Park, Chaewon and Lee, Jungho and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2303.08314},
  year={2023}
}

@article{lee2023tsanet,
  title={TSANET: Temporal and Scale Alignment for Unsupervised Video Object Segmentation},
  author={Lee, Seunghoon and Cho, Suhwan and Lee, Dogyoon and Lee, Minhyeok and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2303.04376},
  year={2023}
}

@article{park2023two,
  title={Two-stream Decoder Feature Normality Estimating Network for Industrial Anomaly Detection},
  author={Park, Chaewon and Lee, Minhyeok and Cho, Suhwan and Kim, Donghyeong and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2302.09794},
  year={2023}
}

@article{lee2022leveraging,
  title={Leveraging Spatio-Temporal Dependency for Skeleton-Based Action Recognition},
  author={Lee, Jungho and Lee, Minhyeok and Cho, Suhwan and Woo, Sungmin and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2212.04761},
  year={2022}
}

@article{lee2022deblurred,
  title={Deblurred Neural Radiance Field with Physical Scene Priors},
  author={Lee, Dogyoon and Lee, Minhyeok and Shin, Chajin and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2211.12046},
  year={2022}
}

@article{cho2022domain,
  title={Domain Alignment and Temporal Aggregation for Unsupervised Video Object Segmentation},
  author={Cho, Suhwan and Lee, Minhyeok and Lee, Seunghoon and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2211.12036},
  year={2022}
}

@article{lee2022global,
  title={Boundary-aware Camouflaged Object Detection via Deformable Point Sampling},
  author={Lee, Minhyeok and Cho, Suhwan and Park, Chaewon and Lee, Dogyoon and Lee, Jungho and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2211.12048},
  year={2022}
}

@article{cho2022pixel,
  title={Pixel-Level Equalized Matching for Video Object Segmentation},
  author={Cho, Suhwan and Kim, Woo Jin and Cho, MyeongAh and Lee, Seunghoon and Lee, Minhyeok and Park, Chaewon and Lee, Sangyoun},
  journal={arXiv preprint arXiv:2209.03139},
  year={2022}
}

@inproceedings{lee2021multi,
  title={Multi-level Feature Maps Attention for Monocular Depth Estimation},
  author={Lee, Seunghoon and Lee, Minhyeok and Lee, Sangyoon},
  booktitle={2021 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)},
  pages={1--4},
  year={2021},
  organization={IEEE}
}
